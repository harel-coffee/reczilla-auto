{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of algorithm performance across datasets and metrics for NeurIPS submission\n",
    "\n",
    "For these tables we use the meta-dataset as for the RecZilla pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./meta_datasets/metadata-v1.1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_family</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>split_name</th>\n",
       "      <th>original_split_path</th>\n",
       "      <th>hyperparameters_source</th>\n",
       "      <th>time_on_val</th>\n",
       "      <th>time_on_test</th>\n",
       "      <th>time_on_train</th>\n",
       "      <th>test_metric_ARHR_ALL_HITS_cut_1</th>\n",
       "      <th>test_metric_ARHR_ALL_HITS_cut_10</th>\n",
       "      <th>...</th>\n",
       "      <th>param_similarity_from_distance_mode</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_symmetric</th>\n",
       "      <th>param_topK</th>\n",
       "      <th>param_total_anneal_steps</th>\n",
       "      <th>param_tversky_alpha</th>\n",
       "      <th>param_tversky_beta</th>\n",
       "      <th>param_use_bias</th>\n",
       "      <th>param_user_reg</th>\n",
       "      <th>alg_param_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UserKNNCF</td>\n",
       "      <td>AmazonElectronicsReader</td>\n",
       "      <td>DataSplitter_leave_k_out_last</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>default</td>\n",
       "      <td>4583.751314</td>\n",
       "      <td>4548.318467</td>\n",
       "      <td>17298.476997</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>...</td>\n",
       "      <td>lin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UserKNNCF:euclidean_default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TopPop</td>\n",
       "      <td>Jester2Reader</td>\n",
       "      <td>DataSplitter_leave_k_out_last</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>default</td>\n",
       "      <td>192.594337</td>\n",
       "      <td>193.140875</td>\n",
       "      <td>0.047207</td>\n",
       "      <td>0.053858</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopPop:default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>IALSRecommender</td>\n",
       "      <td>YahooMoviesReader</td>\n",
       "      <td>DataSplitter_leave_k_out_last</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>default</td>\n",
       "      <td>26.554102</td>\n",
       "      <td>26.568692</td>\n",
       "      <td>606.267164</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IALSRecommender:default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>IALSRecommender</td>\n",
       "      <td>YahooMoviesReader</td>\n",
       "      <td>DataSplitter_leave_k_out_last</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>random_0</td>\n",
       "      <td>26.585350</td>\n",
       "      <td>26.700649</td>\n",
       "      <td>6660.612675</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IALSRecommender:random_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>IALSRecommender</td>\n",
       "      <td>YahooMoviesReader</td>\n",
       "      <td>DataSplitter_leave_k_out_last</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>random_1</td>\n",
       "      <td>26.952350</td>\n",
       "      <td>26.308905</td>\n",
       "      <td>618.663741</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IALSRecommender:random_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          alg_family             dataset_name                     split_name  \\\n",
       "2          UserKNNCF  AmazonElectronicsReader  DataSplitter_leave_k_out_last   \n",
       "34            TopPop            Jester2Reader  DataSplitter_leave_k_out_last   \n",
       "137  IALSRecommender        YahooMoviesReader  DataSplitter_leave_k_out_last   \n",
       "138  IALSRecommender        YahooMoviesReader  DataSplitter_leave_k_out_last   \n",
       "139  IALSRecommender        YahooMoviesReader  DataSplitter_leave_k_out_last   \n",
       "\n",
       "                                   original_split_path hyperparameters_source  \\\n",
       "2    gs://reczilla-results/dataset-splits/splits-v5...                default   \n",
       "34   gs://reczilla-results/dataset-splits/splits-v5...                default   \n",
       "137  gs://reczilla-results/dataset-splits/splits-v5...                default   \n",
       "138  gs://reczilla-results/dataset-splits/splits-v5...               random_0   \n",
       "139  gs://reczilla-results/dataset-splits/splits-v5...               random_1   \n",
       "\n",
       "     time_on_val  time_on_test  time_on_train  \\\n",
       "2    4583.751314   4548.318467   17298.476997   \n",
       "34    192.594337    193.140875       0.047207   \n",
       "137    26.554102     26.568692     606.267164   \n",
       "138    26.585350     26.700649    6660.612675   \n",
       "139    26.952350     26.308905     618.663741   \n",
       "\n",
       "     test_metric_ARHR_ALL_HITS_cut_1  test_metric_ARHR_ALL_HITS_cut_10  ...  \\\n",
       "2                           0.000034                          0.000443  ...   \n",
       "34                          0.053858                          0.147120  ...   \n",
       "137                         0.011777                          0.031597  ...   \n",
       "138                         0.000393                          0.003225  ...   \n",
       "139                         0.009814                          0.030576  ...   \n",
       "\n",
       "     param_similarity_from_distance_mode  param_solver  param_symmetric  \\\n",
       "2                                    lin           NaN              NaN   \n",
       "34                                   NaN           NaN              NaN   \n",
       "137                                  NaN           NaN              NaN   \n",
       "138                                  NaN           NaN              NaN   \n",
       "139                                  NaN           NaN              NaN   \n",
       "\n",
       "     param_topK  param_total_anneal_steps  param_tversky_alpha  \\\n",
       "2           5.0                       NaN                  NaN   \n",
       "34          NaN                       NaN                  NaN   \n",
       "137         NaN                       NaN                  NaN   \n",
       "138         NaN                       NaN                  NaN   \n",
       "139         NaN                       NaN                  NaN   \n",
       "\n",
       "     param_tversky_beta  param_use_bias  param_user_reg  \\\n",
       "2                   NaN             NaN             NaN   \n",
       "34                  NaN             NaN             NaN   \n",
       "137                 NaN             NaN             NaN   \n",
       "138                 NaN             NaN             NaN   \n",
       "139                 NaN             NaN             NaN   \n",
       "\n",
       "                  alg_param_name  \n",
       "2    UserKNNCF:euclidean_default  \n",
       "34                TopPop:default  \n",
       "137      IALSRecommender:default  \n",
       "138     IALSRecommender:random_0  \n",
       "139     IALSRecommender:random_1  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate best metric for each dataset split, over all algs + hyperparam sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_metric_NDCG_cut_1', 'test_metric_PRECISION_cut_1', 'test_metric_HIT_RATE_cut_1', 'test_metric_MAP_cut_1', 'test_metric_F1_cut_1', 'test_metric_NDCG_cut_2', 'test_metric_PRECISION_cut_2', 'test_metric_HIT_RATE_cut_2', 'test_metric_MAP_cut_2', 'test_metric_F1_cut_2', 'test_metric_NDCG_cut_5', 'test_metric_PRECISION_cut_5', 'test_metric_HIT_RATE_cut_5', 'test_metric_MAP_cut_5', 'test_metric_F1_cut_5', 'test_metric_NDCG_cut_10', 'test_metric_PRECISION_cut_10', 'test_metric_HIT_RATE_cut_10', 'test_metric_MAP_cut_10', 'test_metric_F1_cut_10', 'test_metric_NDCG_cut_50', 'test_metric_PRECISION_cut_50', 'test_metric_HIT_RATE_cut_50', 'test_metric_MAP_cut_50', 'test_metric_F1_cut_50']\n"
     ]
    }
   ],
   "source": [
    "# define a subset of metrics to focus on\n",
    "\n",
    "cuts = [1, 2, 5, 10, 50]\n",
    "metrics = [\"NDCG\", \"PRECISION\", \"HIT_RATE\", \"MAP\", \"F1\"]\n",
    "metric_list = []\n",
    "metric_name_list = []\n",
    "for cut in cuts:\n",
    "    for metric in metrics:\n",
    "        metric_list.append(f\"test_metric_{metric}_cut_{str(cut)}\")\n",
    "        metric_name_list.append(f\"{metric}@{cut}\")\n",
    "\n",
    "print(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_col = \"dataset_name\"\n",
    "\n",
    "# get global min and max values for each metric, for each dataset\n",
    "agg_dict = {\n",
    "    metric: [\"min\", \"max\"]\n",
    "    for metric in metric_list\n",
    "}\n",
    "dataset_metric_bounds = df.groupby(dataset_col).agg(agg_dict).reset_index()\n",
    "dataset_alg_metric_bounds = df.groupby([dataset_col, \"alg_family\"]).agg(agg_dict).reset_index()\n",
    "\n",
    "# move to single index - first for global\n",
    "new_col_names = []\n",
    "for v in dataset_metric_bounds.columns.values:\n",
    "    if v[1] in ['min', 'max']:\n",
    "        new_col_names.append('overall_' + v[1] + '_' + v[0])\n",
    "    else:\n",
    "        new_col_names.append(v[0])\n",
    "        \n",
    "dataset_metric_bounds.columns = new_col_names\n",
    "\n",
    "# move to single index - now for dataset-specific\n",
    "new_col_names = []\n",
    "for v in dataset_alg_metric_bounds.columns.values:\n",
    "    if v[1] in ['min', 'max']:\n",
    "        new_col_names.append(v[1] + '_' + v[0])\n",
    "    else:\n",
    "        new_col_names.append(v[0])\n",
    "\n",
    "dataset_alg_metric_bounds.columns = new_col_names\n",
    "\n",
    "# now merge in dataset-specific metric bounds with dataset+alg metric bounds\n",
    "df_expt = dataset_alg_metric_bounds.merge(dataset_metric_bounds, on=dataset_col, how=\"inner\")\n",
    "\n",
    "# now calculate normalized metric value for each metric\n",
    "for metric in metric_list:\n",
    "    df_expt.loc[:, \"normalized_\" + metric] = (df_expt[\"max_\" + metric] - df_expt[\"overall_min_\" + metric]) / (df_expt[\"overall_max_\" + metric] - df_expt[\"overall_min_\" + metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate ranks of all algs based on the normalized metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: 0\n",
      "alg_family: 0\n",
      "min_test_metric_NDCG_cut_1: 5\n",
      "max_test_metric_NDCG_cut_1: 5\n",
      "min_test_metric_PRECISION_cut_1: 0\n",
      "max_test_metric_PRECISION_cut_1: 0\n",
      "min_test_metric_HIT_RATE_cut_1: 0\n",
      "max_test_metric_HIT_RATE_cut_1: 0\n",
      "min_test_metric_MAP_cut_1: 0\n",
      "max_test_metric_MAP_cut_1: 0\n",
      "min_test_metric_F1_cut_1: 0\n",
      "max_test_metric_F1_cut_1: 0\n",
      "min_test_metric_NDCG_cut_2: 8\n",
      "max_test_metric_NDCG_cut_2: 8\n",
      "min_test_metric_PRECISION_cut_2: 0\n",
      "max_test_metric_PRECISION_cut_2: 0\n",
      "min_test_metric_HIT_RATE_cut_2: 0\n",
      "max_test_metric_HIT_RATE_cut_2: 0\n",
      "min_test_metric_MAP_cut_2: 0\n",
      "max_test_metric_MAP_cut_2: 0\n",
      "min_test_metric_F1_cut_2: 0\n",
      "max_test_metric_F1_cut_2: 0\n",
      "min_test_metric_NDCG_cut_5: 9\n",
      "max_test_metric_NDCG_cut_5: 9\n",
      "min_test_metric_PRECISION_cut_5: 0\n",
      "max_test_metric_PRECISION_cut_5: 0\n",
      "min_test_metric_HIT_RATE_cut_5: 0\n",
      "max_test_metric_HIT_RATE_cut_5: 0\n",
      "min_test_metric_MAP_cut_5: 0\n",
      "max_test_metric_MAP_cut_5: 0\n",
      "min_test_metric_F1_cut_5: 0\n",
      "max_test_metric_F1_cut_5: 0\n",
      "min_test_metric_NDCG_cut_10: 9\n",
      "max_test_metric_NDCG_cut_10: 9\n",
      "min_test_metric_PRECISION_cut_10: 0\n",
      "max_test_metric_PRECISION_cut_10: 0\n",
      "min_test_metric_HIT_RATE_cut_10: 0\n",
      "max_test_metric_HIT_RATE_cut_10: 0\n",
      "min_test_metric_MAP_cut_10: 0\n",
      "max_test_metric_MAP_cut_10: 0\n",
      "min_test_metric_F1_cut_10: 0\n",
      "max_test_metric_F1_cut_10: 0\n",
      "min_test_metric_NDCG_cut_50: 14\n",
      "max_test_metric_NDCG_cut_50: 14\n",
      "min_test_metric_PRECISION_cut_50: 0\n",
      "max_test_metric_PRECISION_cut_50: 0\n",
      "min_test_metric_HIT_RATE_cut_50: 0\n",
      "max_test_metric_HIT_RATE_cut_50: 0\n",
      "min_test_metric_MAP_cut_50: 0\n",
      "max_test_metric_MAP_cut_50: 0\n",
      "min_test_metric_F1_cut_50: 0\n",
      "max_test_metric_F1_cut_50: 0\n"
     ]
    }
   ],
   "source": [
    "# how many nans are there for each metric?\n",
    "for c in dataset_alg_metric_bounds.columns:\n",
    "    print(f\"{c}: {sum(dataset_alg_metric_bounds[c].isna())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rank of each alg within each dataset, for each metric\n",
    "for metric in metric_list:\n",
    "    # rank within dataset\n",
    "    df_expt.loc[:, \"rank_\" + metric] = df_expt.groupby([dataset_col])[\"normalized_\" + metric].rank(method=\"min\", ascending=False).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1: show rank and normalized metrics for all algs, and a sample of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote table to csv: ./tables/table_1_test_metric_NDCG_cut_1.csv and tex: ./tables/table_1_test_metric_NDCG_cut_1.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_PRECISION_cut_1.csv and tex: ./tables/table_1_test_metric_PRECISION_cut_1.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_HIT_RATE_cut_1.csv and tex: ./tables/table_1_test_metric_HIT_RATE_cut_1.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_MAP_cut_1.csv and tex: ./tables/table_1_test_metric_MAP_cut_1.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_F1_cut_1.csv and tex: ./tables/table_1_test_metric_F1_cut_1.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_NDCG_cut_2.csv and tex: ./tables/table_1_test_metric_NDCG_cut_2.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_PRECISION_cut_2.csv and tex: ./tables/table_1_test_metric_PRECISION_cut_2.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_HIT_RATE_cut_2.csv and tex: ./tables/table_1_test_metric_HIT_RATE_cut_2.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_MAP_cut_2.csv and tex: ./tables/table_1_test_metric_MAP_cut_2.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_F1_cut_2.csv and tex: ./tables/table_1_test_metric_F1_cut_2.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_NDCG_cut_5.csv and tex: ./tables/table_1_test_metric_NDCG_cut_5.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_PRECISION_cut_5.csv and tex: ./tables/table_1_test_metric_PRECISION_cut_5.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_HIT_RATE_cut_5.csv and tex: ./tables/table_1_test_metric_HIT_RATE_cut_5.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_MAP_cut_5.csv and tex: ./tables/table_1_test_metric_MAP_cut_5.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_F1_cut_5.csv and tex: ./tables/table_1_test_metric_F1_cut_5.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_NDCG_cut_10.csv and tex: ./tables/table_1_test_metric_NDCG_cut_10.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_PRECISION_cut_10.csv and tex: ./tables/table_1_test_metric_PRECISION_cut_10.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_HIT_RATE_cut_10.csv and tex: ./tables/table_1_test_metric_HIT_RATE_cut_10.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_MAP_cut_10.csv and tex: ./tables/table_1_test_metric_MAP_cut_10.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_F1_cut_10.csv and tex: ./tables/table_1_test_metric_F1_cut_10.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_NDCG_cut_50.csv and tex: ./tables/table_1_test_metric_NDCG_cut_50.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_PRECISION_cut_50.csv and tex: ./tables/table_1_test_metric_PRECISION_cut_50.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_HIT_RATE_cut_50.csv and tex: ./tables/table_1_test_metric_HIT_RATE_cut_50.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_MAP_cut_50.csv and tex: ./tables/table_1_test_metric_MAP_cut_50.tex\n",
      "wrote table to csv: ./tables/table_1_test_metric_F1_cut_50.csv and tex: ./tables/table_1_test_metric_F1_cut_50.tex\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# include cols for these datasets\n",
    "display_datasets = [\n",
    "    \"Movielens1MReader\",\n",
    "    \"Movielens100KReader\",\n",
    "    \"Movielens20MReader\"\n",
    "    \"AmazonMoviesTVReader\",\n",
    "    \"AmazonLuxuryBeautyReader\",\n",
    "    \"AmazonWineReader\"\n",
    "    \"BookCrossingReader\",\n",
    "    \"YahooMoviesReader\",\n",
    "    \"CiaoDVDReader\",\n",
    "    \"MovieTweetingsReader\",\n",
    "    \"AnimeReader\",\n",
    "    \"DatingReader\",\n",
    "    # \"LastFMReader\",  # many NaNs...\n",
    "    \"NetflixPrizeReader\",\n",
    "]\n",
    "\n",
    "for metric_name in metric_list:\n",
    "\n",
    "    display_metric = \"normalized_\" + metric_name\n",
    "    display_rank = \"rank_\" + metric_name\n",
    "\n",
    "    df_expt.loc[:, \"display_text\"] = df_expt.apply(lambda x: \"{:.0f} ({:.2f})\".format(x[display_rank], x[display_metric]), axis=1)\n",
    "\n",
    "    table_1 = df_expt[df_expt[\"dataset_name\"].isin(display_datasets)].pivot(index=\"alg_family\", columns=\"dataset_name\", values=\"display_text\").reset_index()\n",
    "\n",
    "    new_col_names = [c if ~c.endswith(\"Reader\") else c[:-len(\"Reader\")] for c in table_1.columns]\n",
    "    new_col_names[0] = \"Alg.\"\n",
    "    table_1.columns = new_col_names\n",
    "    \n",
    "    # export table 1\n",
    "    csv_name = f\"./tables/table_1_{metric_name}.csv\"\n",
    "    tex_name = f\"./tables/table_1_{metric_name}.tex\"\n",
    "    table_1.to_csv(csv_name, index=False)\n",
    "    with open(tex_name, \"w\") as f:\n",
    "        table_1.to_latex(f, index=False)\n",
    "    print(f\"wrote table to csv: {csv_name} and tex: {tex_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2: show max and min rank over all datasets for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_datasets_table_2 = [\n",
    "#     \"AmazonAllBeautyReader\",\n",
    "#     \"AmazonAllElectronicsReader\",\n",
    "#     \"AmazonAlternativeRockReader\",\n",
    "#     \"AmazonAmazonFashionReader\",\n",
    "#     \"AmazonAmazonInstantVideoReader\",\n",
    "#     \"AmazonAppliancesReader\",\n",
    "#     \"AmazonAppsforAndroidReader\",\n",
    "#     \"AmazonAppstoreforAndroidReader\",\n",
    "#     \"AmazonArtsCraftsSewingReader\",\n",
    "#     \"AmazonAutomotiveReader\",\n",
    "#     \"AmazonBabyReader\",\n",
    "#     \"AmazonBabyProductsReader\",\n",
    "#     \"AmazonBeautyReader\",\n",
    "#     \"AmazonBluesReader\",\n",
    "#     \"AmazonBooksReader\",\n",
    "#     \"AmazonBuyaKindleReader\",\n",
    "#     \"AmazonCDsVinylReader\",\n",
    "#     \"AmazonCellPhonesAccessoriesReader\",\n",
    "#     \"AmazonChristianReader\",\n",
    "#     \"AmazonClassicalReader\",\n",
    "#     \"AmazonClothingShoesJewelryReader\",\n",
    "#     \"AmazonCollectiblesFineArtReader\",\n",
    "#     \"AmazonComputersReader\",\n",
    "#     \"AmazonCountryReader\",\n",
    "#     \"AmazonDanceElectronicReader\",\n",
    "#     \"AmazonDavisReader\",\n",
    "#     \"AmazonDigitalMusicReader\",\n",
    "#     \"AmazonElectronicsReader\",\n",
    "#     \"AmazonFolkReader\",\n",
    "#     \"AmazonGiftCardsReader\",\n",
    "#     # \"AmazonGospelReader\",\n",
    "#     \"AmazonGroceryGourmetFoodReader\",\n",
    "#     \"AmazonHardRockMetalReader\",\n",
    "#     \"AmazonHealthPersonalCareReader\",\n",
    "#     # \"AmazonHomeImprovementReader\",\n",
    "#     \"AmazonHomeKitchenReader\",\n",
    "#     \"AmazonIndustrialScientificReader\",\n",
    "#     \"AmazonInternationalReader\",\n",
    "#     \"AmazonJazzReader\",\n",
    "#     \"AmazonKindleStoreReader\",\n",
    "#     \"AmazonKitchenDiningReader\",\n",
    "#     \"AmazonLatinMusicReader\",\n",
    "#     \"AmazonLuxuryBeautyReader\",\n",
    "#     \"AmazonMagazineSubscriptionsReader\",\n",
    "#     \"AmazonMiscellaneousReader\",\n",
    "#     \"AmazonMoviesTVReader\",\n",
    "#     \"AmazonMP3PlayersAccessoriesReader\",\n",
    "#     \"AmazonMusicalInstrumentsReader\",\n",
    "#     \"AmazonNewAgeReader\",\n",
    "#     \"AmazonOfficeProductsReader\",\n",
    "#     \"AmazonOfficeSchoolSuppliesReader\",\n",
    "#     \"AmazonPatioLawnGardenReader\",\n",
    "#     \"AmazonPetSuppliesReader\",\n",
    "#     \"AmazonPopReader\",\n",
    "#     \"AmazonPurchaseCirclesReader\",\n",
    "#     \"AmazonRapHipHopReader\",\n",
    "#     \"AmazonRBReader\",\n",
    "#     \"AmazonRockReader\",\n",
    "#     \"AmazonSoftwareReader\",\n",
    "#     \"AmazonSportsOutdoorsReader\",\n",
    "#     \"AmazonToolsHomeImprovementReader\",\n",
    "#     \"AmazonToysGamesReader\",\n",
    "#     \"AmazonVideoGamesReader\",\n",
    "#     \"AmazonWineReader\",\n",
    "#     \"Movielens100KReader\",\n",
    "#     \"Movielens10MReader\",\n",
    "#     \"Movielens1MReader\",\n",
    "#     \"Movielens20MReader\",\n",
    "#     \"MovielensHetrec2011Reader\"\n",
    "#     \"YahooMoviesReader\",\n",
    "#     \"YahooMusicReader\"\n",
    "#     \"AnimeReader\",\n",
    "#     \"BookCrossingReader\",\n",
    "#     \"CiaoDVDReader\",\n",
    "#     \"DatingReader\",\n",
    "#     \"EpinionsReader\",\n",
    "#     \"FilmTrustReader\",\n",
    "#     \"FrappeReader\",\n",
    "#     \"GoogleLocalReviewsReader\",\n",
    "#     \"GowallaReader\",\n",
    "#     \"Jester2Reader\",\n",
    "#     \"LastFMReader\",\n",
    "#     \"MarketBiasAmazonReader\",\n",
    "#     \"MarketBiasModClothReader\",\n",
    "#     \"MovieTweetingsReader\",\n",
    "#     \"NetflixPrizeReader\",\n",
    "#     \"RecipesReader\",\n",
    "#     \"WikilensReader\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets to drop: {'AmazonNewAgeReader', 'AmazonCountryReader', 'AmazonHomeImprovementReader', 'YahooMusicReader', 'AmazonAllBeautyReader', 'AmazonFolkReader', 'GowallaReader', 'AmazonBluesReader', 'AmazonHardRockMetalReader', 'AmazonGospelReader', 'AmazonMP3PlayersAccessoriesReader', 'FrappeReader', 'LastFMReader', 'AmazonRapHipHopReader', 'AmazonAllElectronicsReader', 'AmazonCollectiblesFineArtReader', 'AmazonOfficeSchoolSuppliesReader', 'AmazonRockReader', 'AmazonRBReader', 'AmazonAlternativeRockReader', 'AmazonAppstoreforAndroidReader', 'AmazonLatinMusicReader', 'AmazonInternationalReader', 'AmazonComputersReader', 'AmazonWineReader', 'AmazonPopReader'}\n",
      "remaining datasets: 59\n"
     ]
    }
   ],
   "source": [
    "# first show the number of algs with results for each dataset and each metric. (equal to max rank)\n",
    "# only keep datasets which have at least 10 ranked algs for each metric\n",
    "max_rank_table = df_expt.groupby(\"dataset_name\")[[\"rank_\" + m for m in metric_list]].max().reset_index()\n",
    "drop_datasets = []\n",
    "for c in max_rank_table.columns[1:]:\n",
    "    if max_rank_table[c].min() < 10:\n",
    "        # print(f\"WARNING: column {c} has a dataset with only {max_rank_table[c].min()} algs\")\n",
    "        # print(max_rank_table[max_rank_table[c] < 10][[\"dataset_name\", c]])\n",
    "        # print(f\"adding to drop_datasets...\")\n",
    "        drop_datasets.extend(max_rank_table[max_rank_table[c] < 10][\"dataset_name\"])\n",
    "\n",
    "drop_datasets = set(drop_datasets)\n",
    "print(f\"datasets to drop: {drop_datasets}\")\n",
    "\n",
    "df_table_2 = df_expt.loc[~df_expt[\"dataset_name\"].isin(drop_datasets), :]\n",
    "\n",
    "print(f\"remaining datasets: {len(df_table_2['dataset_name'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min and max rank for each alg and each metric over all algs.     each alg = col, row = metric\n",
    "agg_dict = {\n",
    "    \"rank_\" + metric: lambda x: f\"{min(x)} / {max(x)}\" for metric in metric_list\n",
    "}\n",
    "table_2_transpose = df_table_2.groupby(\"alg_family\").agg(agg_dict).reset_index()\n",
    "\n",
    "table_2 = table_2_transpose.transpose()\n",
    "\n",
    "# now fix the metric names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a49d437ec7d70416a2164b1de0841ecb25c4cf254d34094d737b88836beceb4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
